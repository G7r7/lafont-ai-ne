{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gutenbergpy in /usr/local/lib/python3.8/dist-packages (0.3.4)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.8/dist-packages (from gutenbergpy) (4.3.2)\n",
      "Requirement already satisfied: httpsproxy-urllib2 in /usr/local/lib/python3.8/dist-packages (from gutenbergpy) (1.0)\n",
      "Requirement already satisfied: lxml>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from gutenbergpy) (4.9.1)\n",
      "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.8/dist-packages (from gutenbergpy) (0.18.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from gutenbergpy) (65.3.0)\n",
      "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from gutenbergpy) (3.0.4)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from pymongo->gutenbergpy) (2.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Cache already exists\n",
      "0 / 28\n",
      "1 / 28\n",
      "2 / 28\n",
      "3 / 28\n",
      "4 / 28\n",
      "5 / 28\n",
      "6 / 28\n",
      "7 / 28\n",
      "8 / 28\n",
      "9 / 28\n",
      "10 / 28\n",
      "11 / 28\n",
      "12 / 28\n",
      "13 / 28\n",
      "14 / 28\n",
      "15 / 28\n",
      "16 / 28\n",
      "17 / 28\n",
      "18 / 28\n",
      "19 / 28\n",
      "20 / 28\n",
      "21 / 28\n",
      "22 / 28\n",
      "23 / 28\n",
      "24 / 28\n",
      "25 / 28\n",
      "26 / 28\n",
      "27 / 28\n"
     ]
    }
   ],
   "source": [
    "# We download our dataset for the training\n",
    "\n",
    "!pip3 install gutenbergpy\n",
    "import datasource\n",
    "datasource.download_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.8/dist-packages (0.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.23.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (21.3)\n",
      "Requirement already satisfied: tensorflow; platform_system != \"Darwin\" in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-text; platform_system != \"Darwin\" in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras_nlp) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->keras_nlp) (3.0.9)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.48.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (4.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.19.4)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.7.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (65.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.26.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (14.0.6)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.0.7)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text; platform_system != \"Darwin\"->keras_nlp) (0.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.34.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.11.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (2.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (4.9)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (4.12.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow; platform_system != \"Darwin\"->keras_nlp) (3.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keras_nlp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow_text as tf_text\n",
    "import keras_nlp\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "APP_DIR = Path.home() / \".lafontaine\"\n",
    "DATASET = APP_DIR / \"dataset.txt\"\n",
    "VECTORIZER = APP_DIR / \"vectorizer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '[UNK]',\n",
       " 2: 'et',\n",
       " 3: 'de',\n",
       " 4: 'la',\n",
       " 5: 'les',\n",
       " 6: 'le',\n",
       " 7: 'des',\n",
       " 8: 'un',\n",
       " 9: 'à',\n",
       " 10: 'en',\n",
       " 11: 'que',\n",
       " 12: 'qui',\n",
       " 13: 'dans',\n",
       " 14: 'je',\n",
       " 15: 'du',\n",
       " 16: 'au',\n",
       " 17: 'sur',\n",
       " 18: 'son',\n",
       " 19: 'comme',\n",
       " 20: 'pour',\n",
       " 21: 'il',\n",
       " 22: 'est',\n",
       " 23: 'se',\n",
       " 24: 'ce',\n",
       " 25: 'vous',\n",
       " 26: 'une',\n",
       " 27: 'ne',\n",
       " 28: 'plus',\n",
       " 29: 'ses',\n",
       " 30: 'mon',\n",
       " 31: 'sa',\n",
       " 32: 'aux',\n",
       " 33: 'nous',\n",
       " 34: 'par',\n",
       " 35: 'pas',\n",
       " 36: 'où',\n",
       " 37: 'tout',\n",
       " 38: 'leur',\n",
       " 39: 'avec',\n",
       " 40: 'leurs',\n",
       " 41: 'sans',\n",
       " 42: \"d'un\",\n",
       " 43: 'si',\n",
       " 44: 'tu',\n",
       " 45: 'ma',\n",
       " 46: 'mais',\n",
       " 47: 'sous',\n",
       " 48: 'me',\n",
       " 49: 'ton',\n",
       " 50: 'mes',\n",
       " 51: 'ces',\n",
       " 52: 'moi',\n",
       " 53: 'cœur',\n",
       " 54: 'on',\n",
       " 55: 'a',\n",
       " 56: 'sont',\n",
       " 57: 'ou',\n",
       " 58: 'vers',\n",
       " 59: \"c'est\",\n",
       " 60: 'elle',\n",
       " 61: 'dont',\n",
       " 62: 'yeux',\n",
       " 63: 'tes',\n",
       " 64: 'nos',\n",
       " 65: 'tous',\n",
       " 66: 'lui',\n",
       " 67: 'ils',\n",
       " 68: 'fait',\n",
       " 69: 'là',\n",
       " 70: 'bien',\n",
       " 71: 'ciel',\n",
       " 72: 'vos',\n",
       " 73: 'ta',\n",
       " 74: 'quand',\n",
       " 75: 'l',\n",
       " 76: 'même',\n",
       " 77: 'cette',\n",
       " 78: 'jour',\n",
       " 79: 'votre',\n",
       " 80: 'te',\n",
       " 81: \"qu'il\",\n",
       " 82: 'toujours',\n",
       " 83: 'mort',\n",
       " 84: 'toi',\n",
       " 85: 'ont',\n",
       " 86: 'soleil',\n",
       " 87: 'deux',\n",
       " 88: 'dieu',\n",
       " 89: 'notre',\n",
       " 90: \"qu'un\",\n",
       " 91: \"d'une\",\n",
       " 92: 'soir',\n",
       " 93: \"d'or\",\n",
       " 94: 'nuit',\n",
       " 95: 'ainsi',\n",
       " 96: 'rien',\n",
       " 97: 'jamais',\n",
       " 98: \"j'ai\",\n",
       " 99: 'monde',\n",
       " 100: 'âme',\n",
       " 101: \"qu'on\",\n",
       " 102: 'vie',\n",
       " 103: 'temps',\n",
       " 104: 'terre',\n",
       " 105: 'suis',\n",
       " 106: 'grand',\n",
       " 107: 'd',\n",
       " 108: 'car',\n",
       " 109: 'corps',\n",
       " 110: 'encor',\n",
       " 111: 'loin',\n",
       " 112: 'fond',\n",
       " 113: 'bas',\n",
       " 114: 'voix',\n",
       " 115: 'être',\n",
       " 116: 'ni',\n",
       " 117: 'grands',\n",
       " 118: 'donc',\n",
       " 119: 'doux',\n",
       " 120: 'bras',\n",
       " 121: 'vieux',\n",
       " 122: 'front',\n",
       " 123: \"l'on\",\n",
       " 124: 'voir',\n",
       " 125: 'y',\n",
       " 126: \"n'est\",\n",
       " 127: 'mains',\n",
       " 128: 'peut',\n",
       " 129: 'main',\n",
       " 130: 'dit',\n",
       " 131: 'seul',\n",
       " 132: 'vent',\n",
       " 133: 'mer',\n",
       " 134: 'beau',\n",
       " 135: 'fleurs',\n",
       " 136: 'ô',\n",
       " 137: 'amour',\n",
       " 138: 'quel',\n",
       " 139: 'toute',\n",
       " 140: 'sang',\n",
       " 141: 'trop',\n",
       " 142: 'chaque',\n",
       " 143: 'feu',\n",
       " 144: 'devant',\n",
       " 145: 'haut',\n",
       " 146: 'tête',\n",
       " 147: 'entre',\n",
       " 148: 'quelque',\n",
       " 149: 'aussi',\n",
       " 150: 'jours',\n",
       " 151: 'non',\n",
       " 152: 'point',\n",
       " 153: 'était',\n",
       " 154: 'bois',\n",
       " 155: 'va',\n",
       " 156: \"l'amour\",\n",
       " 157: 'tant',\n",
       " 158: 'noir',\n",
       " 159: 'puis',\n",
       " 160: 'moins',\n",
       " 161: 'peu',\n",
       " 162: 'jeune',\n",
       " 163: 'près',\n",
       " 164: 'pieds',\n",
       " 165: 'long',\n",
       " 166: \"l'air\",\n",
       " 167: 'encore',\n",
       " 168: 'femme',\n",
       " 169: 'rêve',\n",
       " 170: 'après',\n",
       " 171: 'lorsque',\n",
       " 172: 'faut',\n",
       " 173: \"s'en\",\n",
       " 174: 'ceux',\n",
       " 175: 'parmi',\n",
       " 176: 'tour',\n",
       " 177: 'lumière',\n",
       " 178: 'fleur',\n",
       " 179: 'autour',\n",
       " 180: \"n'a\",\n",
       " 181: 'cieux',\n",
       " 182: 'belle',\n",
       " 183: 'toutes',\n",
       " 184: 'roi',\n",
       " 185: 'faire',\n",
       " 186: 'qu',\n",
       " 187: \"l'ombre\",\n",
       " 188: 'noirs',\n",
       " 189: 'hélas',\n",
       " 190: 'voici',\n",
       " 191: 'j',\n",
       " 192: 'ah',\n",
       " 193: 'contre',\n",
       " 194: 'gloire',\n",
       " 195: 'font',\n",
       " 196: 'cœurs',\n",
       " 197: 'cet',\n",
       " 198: 'eux',\n",
       " 199: 'coup',\n",
       " 200: 'oh',\n",
       " 201: 'fois',\n",
       " 202: 'veux',\n",
       " 203: 'the',\n",
       " 204: 'nom',\n",
       " 205: \"l'eau\",\n",
       " 206: \"l'homme\",\n",
       " 207: 'bouche',\n",
       " 208: 'voit',\n",
       " 209: 'beauté',\n",
       " 210: 'mille',\n",
       " 211: 's',\n",
       " 212: 'bruit',\n",
       " 213: 'beaux',\n",
       " 214: 'joie',\n",
       " 215: 'alors',\n",
       " 216: 'n',\n",
       " 217: 'fut',\n",
       " 218: 'celui',\n",
       " 219: 'rose',\n",
       " 220: 'plein',\n",
       " 221: 'morts',\n",
       " 222: 'silence',\n",
       " 223: 'homme',\n",
       " 224: 'vois',\n",
       " 225: 'déjà',\n",
       " 226: 'chair',\n",
       " 227: 'avant',\n",
       " 228: 'avait',\n",
       " 229: 'fils',\n",
       " 230: 'mal',\n",
       " 231: 'depuis',\n",
       " 232: 'fer',\n",
       " 233: 'autre',\n",
       " 234: 'enfin',\n",
       " 235: 'bonheur',\n",
       " 236: 'regard',\n",
       " 237: 'clair',\n",
       " 238: 'sens',\n",
       " 239: 'porte',\n",
       " 240: 'nature',\n",
       " 241: 'lune',\n",
       " 242: 'femmes',\n",
       " 243: 'ai',\n",
       " 244: 'pleurs',\n",
       " 245: 'doigts',\n",
       " 246: 'sein',\n",
       " 247: 'mieux',\n",
       " 248: 'hommes',\n",
       " 249: 'flots',\n",
       " 250: 'longs',\n",
       " 251: 'pourquoi',\n",
       " 252: 'cheveux',\n",
       " 253: 'vont',\n",
       " 254: 'rouge',\n",
       " 255: 'ici',\n",
       " 256: 'tel',\n",
       " 257: 'vient',\n",
       " 258: 'soit',\n",
       " 259: 'sais',\n",
       " 260: 'vu',\n",
       " 261: 'ville',\n",
       " 262: 'vain',\n",
       " 263: 'travers',\n",
       " 264: 'pâle',\n",
       " 265: 'm',\n",
       " 266: 'sombre',\n",
       " 267: 'tombe',\n",
       " 268: \"qu'elle\",\n",
       " 269: 'mots',\n",
       " 270: \"l'autre\",\n",
       " 271: 'matin',\n",
       " 272: 'triste',\n",
       " 273: 'cris',\n",
       " 274: 'force',\n",
       " 275: 'très',\n",
       " 276: 'autres',\n",
       " 277: 'lit',\n",
       " 278: 'flamme',\n",
       " 279: 'désir',\n",
       " 280: 'bord',\n",
       " 281: 'sol',\n",
       " 282: \"qu'une\",\n",
       " 283: 'œil',\n",
       " 284: 't',\n",
       " 285: 'sort',\n",
       " 286: 'blanc',\n",
       " 287: 'peur',\n",
       " 288: 'veut',\n",
       " 289: 'regards',\n",
       " 290: 'chemin',\n",
       " 291: 'visage',\n",
       " 292: 'bleu',\n",
       " 293: 'nul',\n",
       " 294: \"l'âme\",\n",
       " 295: 'bout',\n",
       " 296: 'ans',\n",
       " 297: 'enfant',\n",
       " 298: 'choses',\n",
       " 299: 'roses',\n",
       " 300: 'murs',\n",
       " 301: 'blanche',\n",
       " 302: 'feux',\n",
       " 303: 'ailes',\n",
       " 304: 'pur',\n",
       " 305: 'mère',\n",
       " 306: 'laisse',\n",
       " 307: 'soudain',\n",
       " 308: 'reste',\n",
       " 309: 'heureux',\n",
       " 310: 'pourtant',\n",
       " 311: 'gens',\n",
       " 312: 'quelques',\n",
       " 313: 'pied',\n",
       " 314: 'ange',\n",
       " 315: 'peine',\n",
       " 316: 'pauvre',\n",
       " 317: \"l'œil\",\n",
       " 318: \"l'or\",\n",
       " 319: 'voilà',\n",
       " 320: 'semble',\n",
       " 321: 'dieux',\n",
       " 322: 'elles',\n",
       " 323: 'douleur',\n",
       " 324: \"qu'ils\",\n",
       " 325: 'peuple',\n",
       " 326: 'petit',\n",
       " 327: 'douce',\n",
       " 328: 'pays',\n",
       " 329: 'moment',\n",
       " 330: 'foule',\n",
       " 331: \"d'autres\",\n",
       " 332: 'souvenir',\n",
       " 333: 'songe',\n",
       " 334: \"s'il\",\n",
       " 335: 'esprit',\n",
       " 336: \"d'amour\",\n",
       " 337: 'blancs',\n",
       " 338: 'été',\n",
       " 339: 'quoi',\n",
       " 340: 'neige',\n",
       " 341: 'maître',\n",
       " 342: 'vin',\n",
       " 343: 'saint',\n",
       " 344: 'seule',\n",
       " 345: \"s'est\",\n",
       " 346: \"qu'à\",\n",
       " 347: 'parfois',\n",
       " 348: 'chose',\n",
       " 349: 'cela',\n",
       " 350: 'regarde',\n",
       " 351: \"qu'en\",\n",
       " 352: 'pierre',\n",
       " 353: 'nouveau',\n",
       " 354: 'larmes',\n",
       " 355: \"l'heure\",\n",
       " 356: 'dire',\n",
       " 357: \"c'était\",\n",
       " 358: 'sommes',\n",
       " 359: 'quelle',\n",
       " 360: 'orgueil',\n",
       " 361: 'fin',\n",
       " 362: 'passé',\n",
       " 363: 'fort',\n",
       " 364: 'fille',\n",
       " 365: 'baisers',\n",
       " 366: 'baiser',\n",
       " 367: \"n'ai\",\n",
       " 368: 'immense',\n",
       " 369: 'croix',\n",
       " 370: 'cependant',\n",
       " 371: 'souvent',\n",
       " 372: 'sait',\n",
       " 373: 'palais',\n",
       " 374: 'grande',\n",
       " 375: 'quels',\n",
       " 376: 'pensée',\n",
       " 377: 'passe',\n",
       " 378: 'or',\n",
       " 379: 'lèvres',\n",
       " 380: \"d'argent\",\n",
       " 381: 'milieu',\n",
       " 382: 'debout',\n",
       " 383: 'chemins',\n",
       " 384: 'chante',\n",
       " 385: 'bientôt',\n",
       " 386: 'route',\n",
       " 387: 'longtemps',\n",
       " 388: 'as',\n",
       " 389: 'pluie',\n",
       " 390: 'plaisir',\n",
       " 391: 'jardin',\n",
       " 392: 'frais',\n",
       " 393: 'tendre',\n",
       " 394: 'paix',\n",
       " 395: 'of',\n",
       " 396: 'champs',\n",
       " 397: 'vol',\n",
       " 398: 'partout',\n",
       " 399: 'oiseaux',\n",
       " 400: 'héros',\n",
       " 401: 'genoux',\n",
       " 402: 'foi',\n",
       " 403: 'face',\n",
       " 404: 'dis',\n",
       " 405: 'bon',\n",
       " 406: 'air',\n",
       " 407: 'rois',\n",
       " 408: 'mourir',\n",
       " 409: \"l'univers\",\n",
       " 410: \"jusqu'au\",\n",
       " 411: 'jadis',\n",
       " 412: \"d'être\",\n",
       " 413: 'divin',\n",
       " 414: 'tombeau',\n",
       " 415: 'souffle',\n",
       " 416: 'soirs',\n",
       " 417: 'sera',\n",
       " 418: 'large',\n",
       " 419: \"l'esprit\",\n",
       " 420: 'vivre',\n",
       " 421: 'tandis',\n",
       " 422: 'mot',\n",
       " 423: 'heure',\n",
       " 424: 'chez',\n",
       " 425: 'premier',\n",
       " 426: 'livre',\n",
       " 427: 'dents',\n",
       " 428: 'coups',\n",
       " 429: 'rire',\n",
       " 430: 'pouvoir',\n",
       " 431: \"jusqu'à\",\n",
       " 432: 'fit',\n",
       " 433: 'printemps',\n",
       " 434: 'paris',\n",
       " 435: \"n'ont\",\n",
       " 436: 'maintenant',\n",
       " 437: 'sommeil',\n",
       " 438: 'lieu',\n",
       " 439: 'dites',\n",
       " 440: 'avoir',\n",
       " 441: 'trois',\n",
       " 442: 'maison',\n",
       " 443: 'france',\n",
       " 444: 'dessus',\n",
       " 445: 'avons',\n",
       " 446: 'rayon',\n",
       " 447: 'profonde',\n",
       " 448: 'nuits',\n",
       " 449: 'mêmes',\n",
       " 450: 'froid',\n",
       " 451: 'viens',\n",
       " 452: 'savoir',\n",
       " 453: 'cri',\n",
       " 454: 'cher',\n",
       " 455: 'vagues',\n",
       " 456: 'lourds',\n",
       " 457: \"l'horizon\",\n",
       " 458: 'joyeux',\n",
       " 459: 'jeunes',\n",
       " 460: \"d'où\",\n",
       " 461: 'clarté',\n",
       " 462: 'celle',\n",
       " 463: 'calme',\n",
       " 464: 'arbres',\n",
       " 465: 'traits',\n",
       " 466: 'seuls',\n",
       " 467: 'rêves',\n",
       " 468: 'rayons',\n",
       " 469: 'enfants',\n",
       " 470: 'doute',\n",
       " 471: 'dos',\n",
       " 472: 'chacun',\n",
       " 473: 'avez',\n",
       " 474: 'amis',\n",
       " 475: 'vrai',\n",
       " 476: 'soldats',\n",
       " 477: 'part',\n",
       " 478: 'chants',\n",
       " 479: 'êtes',\n",
       " 480: 'seins',\n",
       " 481: 'pendant',\n",
       " 482: 'chant',\n",
       " 483: 'vit',\n",
       " 484: 'vide',\n",
       " 485: 'vert',\n",
       " 486: 'secret',\n",
       " 487: 'robe',\n",
       " 488: 'joue',\n",
       " 489: 'fais',\n",
       " 490: 'coin',\n",
       " 491: 'charles',\n",
       " 492: 'and',\n",
       " 493: 'sœur',\n",
       " 494: 'morne',\n",
       " 495: 'malgré',\n",
       " 496: \"aujourd'hui\",\n",
       " 497: 'étrange',\n",
       " 498: 'raison',\n",
       " 499: 'profond',\n",
       " 500: 'place',\n",
       " 501: 'noire',\n",
       " 502: 'las',\n",
       " 503: 'doit',\n",
       " 504: 'comment',\n",
       " 505: 'petits',\n",
       " 506: 'oui',\n",
       " 507: 'ombre',\n",
       " 508: 'combien',\n",
       " 509: 'clairs',\n",
       " 510: 'amours',\n",
       " 511: 'vieille',\n",
       " 512: 'suprême',\n",
       " 513: 'splendeur',\n",
       " 514: 'nuages',\n",
       " 515: \"l'un\",\n",
       " 516: 'jaloux',\n",
       " 517: 'doucement',\n",
       " 518: 'cours',\n",
       " 519: 'c',\n",
       " 520: \"j'aime\",\n",
       " 521: 'deuil',\n",
       " 522: 'cerveau',\n",
       " 523: 'sourire',\n",
       " 524: 'reine',\n",
       " 525: 'pâles',\n",
       " 526: \"l'avenir\",\n",
       " 527: 'adieu',\n",
       " 528: 'vierge',\n",
       " 529: 'grâce',\n",
       " 530: 'donne',\n",
       " 531: 'demeure',\n",
       " 532: 'étaient',\n",
       " 533: 'roule',\n",
       " 534: 'rage',\n",
       " 535: 'monte',\n",
       " 536: 'heures',\n",
       " 537: 'eh',\n",
       " 538: 'eaux',\n",
       " 539: 'vague',\n",
       " 540: 'pris',\n",
       " 541: \"m'a\",\n",
       " 542: 'flot',\n",
       " 543: 'vents',\n",
       " 544: 'tours',\n",
       " 545: 'siècle',\n",
       " 546: 'pitié',\n",
       " 547: \"n'en\",\n",
       " 548: 'mystère',\n",
       " 549: 'marbre',\n",
       " 550: 'lentement',\n",
       " 551: 'jeunesse',\n",
       " 552: 'haine',\n",
       " 553: 'guerre',\n",
       " 554: 'espoir',\n",
       " 555: 'dernier',\n",
       " 556: 'quatre',\n",
       " 557: 'pleure',\n",
       " 558: 'marche',\n",
       " 559: 'dès',\n",
       " 560: 'crois',\n",
       " 561: 'pu',\n",
       " 562: 'prend',\n",
       " 563: 'petite',\n",
       " 564: 'noble',\n",
       " 565: 'forme',\n",
       " 566: 'eût',\n",
       " 567: 'cheval',\n",
       " 568: 'vénus',\n",
       " 569: 'lourd',\n",
       " 570: 'fleuve',\n",
       " 571: 'feuilles',\n",
       " 572: 'douleurs',\n",
       " 573: 'cour',\n",
       " 574: 'ami',\n",
       " 575: 'aime',\n",
       " 576: 'vainqueur',\n",
       " 577: 'temple',\n",
       " 578: 'sainte',\n",
       " 579: 'pleins',\n",
       " 580: 'parfums',\n",
       " 581: 'folle',\n",
       " 582: 'droit',\n",
       " 583: 'derrière',\n",
       " 584: 'cité',\n",
       " 585: 'charmant',\n",
       " 586: 'boire',\n",
       " 587: 'seuil',\n",
       " 588: 'rouges',\n",
       " 589: 'repos',\n",
       " 590: 'nuage',\n",
       " 591: 'mémoire',\n",
       " 592: 'lois',\n",
       " 593: 'couleur',\n",
       " 594: 'cent',\n",
       " 595: 'quint',\n",
       " 596: 'première',\n",
       " 597: 'manteau',\n",
       " 598: 'fier',\n",
       " 599: 'demain',\n",
       " 600: 'côté',\n",
       " 601: 'autant',\n",
       " 602: 'soi',\n",
       " 603: 'prendre',\n",
       " 604: 'parfum',\n",
       " 605: 'néant',\n",
       " 606: 'lointains',\n",
       " 607: \"l'art\",\n",
       " 608: 'jette',\n",
       " 609: 'fous',\n",
       " 610: 'blanches',\n",
       " 611: 'aile',\n",
       " 612: 'telle',\n",
       " 613: 'père',\n",
       " 614: 'plaine',\n",
       " 615: 'in',\n",
       " 616: 'ferme',\n",
       " 617: \"d'eau\",\n",
       " 618: 'assez',\n",
       " 619: 'aller',\n",
       " 620: 'voiles',\n",
       " 621: 'parle',\n",
       " 622: 'flammes',\n",
       " 623: 'couleurs',\n",
       " 624: 'assis',\n",
       " 625: 'vivant',\n",
       " 626: 'ventre',\n",
       " 627: 'vaste',\n",
       " 628: 'peau',\n",
       " 629: \"l'orgueil\",\n",
       " 630: \"l'espace\",\n",
       " 631: 'chevaux',\n",
       " 632: 'cesse',\n",
       " 633: 'bleus',\n",
       " 634: 'verts',\n",
       " 635: 'ténèbres',\n",
       " 636: 'tient',\n",
       " 637: 'chanter',\n",
       " 638: 'trouve',\n",
       " 639: \"s'y\",\n",
       " 640: 'présent',\n",
       " 641: 'poëte',\n",
       " 642: 'personne',\n",
       " 643: 'passer',\n",
       " 644: 'musique',\n",
       " 645: 'miroir',\n",
       " 646: 'libre',\n",
       " 647: 'destin',\n",
       " 648: 'court',\n",
       " 649: 'auprès',\n",
       " 650: 'âmes',\n",
       " 651: 'voile',\n",
       " 652: 'vingt',\n",
       " 653: 'vermeil',\n",
       " 654: 'superbe',\n",
       " 655: 'sois',\n",
       " 656: 'pleine',\n",
       " 657: 'met',\n",
       " 658: 'lieux',\n",
       " 659: \"l'herbe\",\n",
       " 660: 'gros',\n",
       " 661: 'fou',\n",
       " 662: 'couronne',\n",
       " 663: 'bonne',\n",
       " 664: 'vais',\n",
       " 665: 'to',\n",
       " 666: 'rendre',\n",
       " 667: \"qu'au\",\n",
       " 668: 'prince',\n",
       " 669: 'plaines',\n",
       " 670: 'pauvres',\n",
       " 671: 'meurt',\n",
       " 672: 'loi',\n",
       " 673: \"l'hiver\",\n",
       " 674: 'instant',\n",
       " 675: 'gouffre',\n",
       " 676: 'suivre',\n",
       " 677: 'plaisirs',\n",
       " 678: 'midi',\n",
       " 679: 'maisons',\n",
       " 680: 'fête',\n",
       " 681: 'fruits',\n",
       " 682: \"d'avoir\",\n",
       " 683: 'chambre',\n",
       " 684: 'étoiles',\n",
       " 685: 'âge',\n",
       " 686: 'rome',\n",
       " 687: 'reflet',\n",
       " 688: 'pure',\n",
       " 689: 'proie',\n",
       " 690: 'poète',\n",
       " 691: 'pourpre',\n",
       " 692: 'morte',\n",
       " 693: 'maux',\n",
       " 694: \"l'infini\",\n",
       " 695: 'désert',\n",
       " 696: 'douceur',\n",
       " 697: 'croit',\n",
       " 698: 'brille',\n",
       " 699: 'ardeur',\n",
       " 700: 'vertu',\n",
       " 701: 'toits',\n",
       " 702: 'terrible',\n",
       " 703: 'rit',\n",
       " 704: 'prière',\n",
       " 705: 'poids',\n",
       " 706: 'nombre',\n",
       " 707: \"n'y\",\n",
       " 708: 'mis',\n",
       " 709: 'liberté',\n",
       " 710: 'humains',\n",
       " 711: 'geste',\n",
       " 712: 'fronts',\n",
       " 713: 'folie',\n",
       " 714: 'filles',\n",
       " 715: 'dame',\n",
       " 716: 'voyage',\n",
       " 717: 'trône',\n",
       " 718: 'tranquille',\n",
       " 719: 'sublime',\n",
       " 720: 'soleils',\n",
       " 721: 'pense',\n",
       " 722: 'passant',\n",
       " 723: 'ombres',\n",
       " 724: 'nus',\n",
       " 725: 'nord',\n",
       " 726: 'mers',\n",
       " 727: \"l'aube\",\n",
       " 728: 'garde',\n",
       " 729: 'but',\n",
       " 730: 'brise',\n",
       " 731: 'bords',\n",
       " 732: 'belles',\n",
       " 733: 'éternel',\n",
       " 734: 'voudrais',\n",
       " 735: 'trésor',\n",
       " 736: 'trouver',\n",
       " 737: 'souvenirs',\n",
       " 738: 'sable',\n",
       " 739: 'puisque',\n",
       " 740: 'jésus',\n",
       " 741: 'fenêtre',\n",
       " 742: 'faux',\n",
       " 743: 'eau',\n",
       " 744: 'creux',\n",
       " 745: 'anges',\n",
       " 746: 'tristesse',\n",
       " 747: 'riche',\n",
       " 748: 'portes',\n",
       " 749: 'pensées',\n",
       " 750: 'larges',\n",
       " 751: 'divine',\n",
       " 752: 'antique',\n",
       " 753: 'afin',\n",
       " 754: 'vue',\n",
       " 755: 'tomber',\n",
       " 756: 'solitaire',\n",
       " 757: 'serait',\n",
       " 758: 'rue',\n",
       " 759: 'nouvelle',\n",
       " 760: 'lointain',\n",
       " 761: \"jusqu'aux\",\n",
       " 762: 'entend',\n",
       " 763: 'col',\n",
       " 764: 'christ',\n",
       " 765: 'ame',\n",
       " 766: 'tels',\n",
       " 767: 'silencieux',\n",
       " 768: 'rapide',\n",
       " 769: 'perdu',\n",
       " 770: 'nouveaux',\n",
       " 771: 'montagne',\n",
       " 772: 'lèvre',\n",
       " 773: 'frère',\n",
       " 774: 'entier',\n",
       " 775: 'désirs',\n",
       " 776: 'dort',\n",
       " 777: 'vis',\n",
       " 778: 'têtes',\n",
       " 779: 'plis',\n",
       " 780: 'nu',\n",
       " 781: 'mur',\n",
       " 782: 'masque',\n",
       " 783: \"j'avais\",\n",
       " 784: 'haute',\n",
       " 785: 'gorge',\n",
       " 786: 'flancs',\n",
       " 787: 'descend',\n",
       " 788: \"d'airain\",\n",
       " 789: 'branches',\n",
       " 790: 'ayant',\n",
       " 791: 'airs',\n",
       " 792: 'secrets',\n",
       " 793: 'retour',\n",
       " 794: 'génie',\n",
       " 795: 'fuit',\n",
       " 796: 'droits',\n",
       " 797: 'doigt',\n",
       " 798: 'diable',\n",
       " 799: 'delà',\n",
       " 800: 'connais',\n",
       " 801: 'astres',\n",
       " 802: 'vérité',\n",
       " 803: 'voyant',\n",
       " 804: 'villes',\n",
       " 805: 'venir',\n",
       " 806: 'velours',\n",
       " 807: 'table',\n",
       " 808: 'suit',\n",
       " 809: 'sentir',\n",
       " 810: 'poésie',\n",
       " 811: 'peuples',\n",
       " 812: 'paradis',\n",
       " 813: 'obscur',\n",
       " 814: 'o',\n",
       " 815: 'nid',\n",
       " 816: \"l'onde\",\n",
       " 817: \"j'en\",\n",
       " 818: 'hors',\n",
       " 819: 'faisait',\n",
       " 820: \"d'azur\",\n",
       " 821: \"d'abord\",\n",
       " 822: 'chiens',\n",
       " 823: 'autrefois',\n",
       " 824: 'aucun',\n",
       " 825: 'arbre',\n",
       " 826: 'allons',\n",
       " 827: 'seront',\n",
       " 828: 'saints',\n",
       " 829: 'rend',\n",
       " 830: 'purs',\n",
       " 831: 'pousse',\n",
       " 832: 'pareils',\n",
       " 833: 'mois',\n",
       " 834: 'jaune',\n",
       " 835: 'français',\n",
       " 836: 'entière',\n",
       " 837: 'danse',\n",
       " 838: 'courage',\n",
       " 839: 'ardente',\n",
       " 840: 'œuvre',\n",
       " 841: 'vive',\n",
       " 842: 'sons',\n",
       " 843: 'sent',\n",
       " 844: 'humain',\n",
       " 845: 'funèbres',\n",
       " 846: 'es',\n",
       " 847: 'demi',\n",
       " 848: 'coupe',\n",
       " 849: 'connu',\n",
       " 850: 'chœur',\n",
       " 851: 'charme',\n",
       " 852: 'énorme',\n",
       " 853: 'travail',\n",
       " 854: 'tard',\n",
       " 855: 'sombres',\n",
       " 856: 'soie',\n",
       " 857: 'seigneur',\n",
       " 858: 'routes',\n",
       " 859: 'puissance',\n",
       " 860: 'poitrine',\n",
       " 861: 'perles',\n",
       " 862: 'paroles',\n",
       " 863: 'ouvre',\n",
       " 864: 'monts',\n",
       " 865: 'lève',\n",
       " 866: 'luit',\n",
       " 867: 'lueurs',\n",
       " 868: 'lampe',\n",
       " 869: 'hasard',\n",
       " 870: 'dirait',\n",
       " 871: 'cou',\n",
       " 872: 'ci',\n",
       " 873: 'cherche',\n",
       " 874: 'toit',\n",
       " 875: 'roux',\n",
       " 876: \"qu'importe\",\n",
       " 877: 'passent',\n",
       " 878: 'parce',\n",
       " 879: 'paraît',\n",
       " 880: 'naître',\n",
       " 881: 'jeux',\n",
       " 882: \"j'étais\",\n",
       " 883: 'goût',\n",
       " 884: 'forêts',\n",
       " 885: 'faisant',\n",
       " 886: 'dur',\n",
       " 887: 'croire',\n",
       " 888: 'crainte',\n",
       " 889: 'change',\n",
       " 890: 'campagne',\n",
       " 891: 'cache',\n",
       " 892: 'bruits',\n",
       " 893: 'voyez',\n",
       " 894: 'vite',\n",
       " 895: 'tourne',\n",
       " 896: 'that',\n",
       " 897: 'su',\n",
       " 898: 'science',\n",
       " 899: 'prix',\n",
       " 900: 'os',\n",
       " 901: 'maîtresse',\n",
       " 902: 'mauvais',\n",
       " 903: 'lys',\n",
       " 904: \"l'ange\",\n",
       " 905: 'gris',\n",
       " 906: 'fuir',\n",
       " 907: 'fidèle',\n",
       " 908: 'crime',\n",
       " 909: 'armes',\n",
       " 910: 'aimer',\n",
       " 911: 'semblait',\n",
       " 912: 'puissant',\n",
       " 913: 'pose',\n",
       " 914: \"n'était\",\n",
       " 915: 'mornes',\n",
       " 916: 'longue',\n",
       " 917: \"l'azur\",\n",
       " 918: 'image',\n",
       " 919: 'glace',\n",
       " 920: 'fureur',\n",
       " 921: 'fil',\n",
       " 922: 'feuille',\n",
       " 923: 'fantôme',\n",
       " 924: 'faits',\n",
       " 925: 'entends',\n",
       " 926: 'combat',\n",
       " 927: 'chère',\n",
       " 928: 'chef',\n",
       " 929: 'siècles',\n",
       " 930: 'semblent',\n",
       " 931: 'oiseau',\n",
       " 932: 'nez',\n",
       " 933: 'mystérieux',\n",
       " 934: 'montre',\n",
       " 935: 'moines',\n",
       " 936: 'malheureux',\n",
       " 937: 'humaine',\n",
       " 938: 'gestes',\n",
       " 939: 'faites',\n",
       " 940: 'dormir',\n",
       " 941: 'devient',\n",
       " 942: 'dernière',\n",
       " 943: 'chanson',\n",
       " 944: 'art',\n",
       " 945: 'ardent',\n",
       " 946: 'époux',\n",
       " 947: 'vieilles',\n",
       " 948: 'teint',\n",
       " 949: 'seulement',\n",
       " 950: 'rosée',\n",
       " 951: 'riant',\n",
       " 952: 'remords',\n",
       " 953: 'plomb',\n",
       " 954: 'monstre',\n",
       " 955: 'lac',\n",
       " 956: \"l'enfant\",\n",
       " 957: 'fumée',\n",
       " 958: 'froide',\n",
       " 959: 'entendre',\n",
       " 960: 'discours',\n",
       " 961: \"d'ébène\",\n",
       " 962: \"d'elle\",\n",
       " 963: 'éclat',\n",
       " 964: 'vraiment',\n",
       " 965: 'verre',\n",
       " 966: 'trouble',\n",
       " 967: 'théâtre',\n",
       " 968: 'terreur',\n",
       " 969: 'ouverte',\n",
       " 970: 'malheur',\n",
       " 971: \"m'en\",\n",
       " 972: 'langue',\n",
       " 973: \"l'espoir\",\n",
       " 974: \"l'enfer\",\n",
       " 975: \"l'aurore\",\n",
       " 976: 'grandes',\n",
       " 977: 'frêle',\n",
       " 978: 'forêt',\n",
       " 979: 'fiers',\n",
       " 980: 'démons',\n",
       " 981: 'double',\n",
       " 982: 'don',\n",
       " 983: 'dix',\n",
       " 984: 'chercher',\n",
       " 985: 'cause',\n",
       " 986: 'blonde',\n",
       " 987: 'étoile',\n",
       " 988: 'volonté',\n",
       " 989: 'vaut',\n",
       " 990: 'uns',\n",
       " 991: 'tremble',\n",
       " 992: 'sûr',\n",
       " 993: 'sourit',\n",
       " 994: 'sortir',\n",
       " 995: 'sacré',\n",
       " 996: 'poissons',\n",
       " 997: 'peux',\n",
       " 998: 'penche',\n",
       " 999: 'parler',\n",
       " ...}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with DATASET.open('r') as stream:\n",
    "    verses = stream.read().splitlines()\n",
    "    verses = verses[0:10000]    \n",
    "    verses = [' '.join(v.split(' ')[::-1]) for v in verses]\n",
    "    \n",
    "print(len(verses))   \n",
    "print(verses[0])\n",
    "\n",
    "    \n",
    "# We force it at 50 or it won't fit in GPU memory\n",
    "seq_length = len(max(verses, key=lambda v: len(v.split())))\n",
    "# seq_length = 50\n",
    "\n",
    "\n",
    "def nw_split(text_input):\n",
    "    splitted = tf_text.regex_split(input=text_input,\n",
    "            delim_regex_pattern=\"[^\\[a-zA-ZÀ-ÿœ']+|\\s+\", # We split on french words and punctuations\n",
    "            keep_delim_regex_pattern=\"[a-zA-ZÀ-ÿœ']\" # We keep everything that isn't a sequence of whitespaces\n",
    "            )\n",
    "    return splitted\n",
    "\n",
    "vectorizer = TextVectorization(\n",
    "    split=nw_split,\n",
    "    standardize='lower',\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=seq_length + 1,\n",
    ")\n",
    "\n",
    "vectorizer.adapt(verses)\n",
    "vocab = vectorizer.get_vocabulary()\n",
    "vocab_size = len(vocab)\n",
    "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
    "\n",
    "index_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(verses)\n",
    "length = len(verses)\n",
    "text_train = verses[:int(0.7*length)]\n",
    "text_test = verses[int(0.7*length):int(0.85*length)]\n",
    "text_valid = verses[int(0.85*length):]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(text_train)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=256)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(text_test)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=256)\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(text_valid)\n",
    "valid_dataset = valid_dataset.shuffle(buffer_size=256)\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    tokenized_sentences = vectorizer(text)\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "    return x, y\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_text)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess_text)\n",
    "test_dataset = test_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "valid_dataset = valid_dataset.map(preprocess_text)\n",
    "valid_dataset = valid_dataset.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 67)]              0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, 67, 128)          4521600   \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_decoder (Transf  (None, 67, 128)          99584     \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 67, 35258)         4548282   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,169,466\n",
      "Trainable params: 9,169,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "num_heads = 4\n",
    "\n",
    "def create_model():\n",
    "    inputs = keras.layers.Input(shape=(seq_length,), dtype=tf.int32)\n",
    "    embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(vocab_size, seq_length, embed_dim)(inputs)\n",
    "    decoder = keras_nlp.layers.TransformerDecoder(intermediate_dim=embed_dim, \n",
    "                                                            num_heads=num_heads, \n",
    "                                                            dropout=0.5)(embedding_layer)\n",
    "    \n",
    "    outputs = keras.layers.Dense(vocab_size, activation='softmax')(decoder)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=\"adam\", \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=[keras_nlp.metrics.Perplexity(), 'accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSampler(keras.callbacks.Callback):\n",
    "    def __init__(self, start_prompt, max_tokens):\n",
    "        self.start_prompt = start_prompt\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "    # Helper method to choose a word from the top K probable words with respect to their probabilities\n",
    "    # in a sequence\n",
    "    def sample_token(self, logits):\n",
    "        logits, indices = tf.math.top_k(logits, k=5, sorted=True)\n",
    "        indices = np.asarray(indices).astype(\"int32\")\n",
    "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = np.asarray(preds).astype(\"float32\")\n",
    "        return np.random.choice(indices, p=preds)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        decoded_sample = self.start_prompt\n",
    "        \n",
    "        for i in range(self.max_tokens-1):\n",
    "            tokenized_prompt = vectorizer([decoded_sample])[:, :-1]\n",
    "            predictions = self.model.predict([tokenized_prompt], verbose=0)\n",
    "            # To find the index of the next word in the prediction array.\n",
    "            # The tokenized prompt is already shorter than the original decoded sample\n",
    "            # by one, len(decoded_sample.split()) is two words ahead - so we remove 1 to get\n",
    "            # the next word in the sequence\n",
    "            sample_index = len(decoded_sample.strip().split())-1\n",
    "            \n",
    "            sampled_token = self.sample_token(predictions[0][sample_index])\n",
    "            sampled_token = index_lookup[sampled_token]\n",
    "            decoded_sample += \" \" + sampled_token\n",
    "            \n",
    "        print(f\"\\nSample text:\\n{decoded_sample}...\\n\")\n",
    "\n",
    "# First 5 words of a random sentence to be used as a seed\n",
    "random_sentence = ' '.join(random.choice(text_valid).replace('\\n', ' ').split(' ')[:4])\n",
    "\n",
    "# Sampler from seed\n",
    "sampler = TextSampler(random_sentence, 30)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reducelr = keras.callbacks.ReduceLROnPlateau(patience=10, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "#history = model.fit(train_dataset, \n",
    "#                    validation_data=valid_dataset,\n",
    "#                    epochs=15, \n",
    "#                    callbacks=[sampler, reducelr])\n",
    "# Save model\n",
    "#model.save(\"sentence_model\")\n",
    "model = keras.models.load_model(\"sentence_model\", compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_token(logits):\n",
    "        logits, indices = tf.math.top_k(logits, k=5, sorted=True)\n",
    "        indices = np.asarray(indices).astype(\"int32\")\n",
    "        preds = keras.activations.softmax(tf.expand_dims(logits, 0))[0]\n",
    "        preds = np.asarray(preds).astype(\"float32\")\n",
    "        return np.random.choice(indices, p=preds)\n",
    "\n",
    "def generate_text(prompt, response_length=20):\n",
    "    decoded_sample = prompt\n",
    "    for i in range(response_length-1):\n",
    "        tokenized_prompt = vectorizer([decoded_sample])[:, :-1]\n",
    "        predictions = model.predict([tokenized_prompt], verbose=0)\n",
    "        sample_index = len(decoded_sample.strip().split())-1\n",
    "        sampled_token = sample_token(predictions[0][sample_index])\n",
    "        sampled_token = index_lookup[sampled_token]\n",
    "        decoded_sample += \" \" + sampled_token\n",
    "    return decoded_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nous sommes deux nous nous avons daté les ans  elle à sa voix  de ce un  n'a\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(\"Nous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
